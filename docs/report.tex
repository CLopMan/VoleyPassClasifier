%----------
%   IMPORTANTE
%----------

% Si nunca has utilizado LaTeX es conveniente que aprendas una serie de conceptos básicos antes de utilizar esta plantilla. Te aconsejamos que leas previamente algún tutorial (puedes encontar muchos en Internet).

% Esta plantilla está basada en las recomendaciones de la guía "Trabajo fin de Grado: Escribir el TFG", que encontrarás en http://uc3m.libguides.com/TFG/escribir
% contiene recomendaciones de la Biblioteca basadas principalmente en estilos APA e IEEE, pero debes seguir siempre las orientaciones de tu Tutor de TFG y la normativa de TFG para tu titulación.

% Encontrarás un ejemplo de TFG realizado con esta misma plantilla en la carpeta "_ejemplo_TFG_2019". Consúltalo porque contiene ejemplos útiles para incorporar tablas, figuras, listados de código, bibliografía, etc.


%----------
%    CONFIGURACIÓN DEL DOCUMENTO
%----------

% Definimos las características del documento y añadimos una serie de paquetes (\usepackage{package}) que agregan funcionalidades a LaTeX.

\documentclass[12pt]{report} %fuente a 12pt

% MÁRGENES: 2,5 cm sup. e inf.; 3 cm izdo. y dcho.
\usepackage[
a4paper,
vmargin=2.5cm,
hmargin=3cm
]{geometry}

% INTERLINEADO: Estrecho (6 ptos./interlineado 1,15) o Moderado (6 ptos./interlineado 1,5)
\renewcommand{\baselinestretch}{1.15}
\parskip=6pt

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% DEFINICIÓN DE COLORES para portada y listados de código
\usepackage[table,dvipsnames]{xcolor}
\definecolor{azulUC3M}{RGB}{0,0,102}
\definecolor{gray97}{gray}{.97}
\definecolor{gray75}{gray}{.75}
\definecolor{gray45}{gray}{.45}

\usepackage{tikz}
\usepackage{pgfplots}
% Soporte para GENERAR PDF/A --es importante de cara a su inclusión en e-Archivo porque es el formato óptimo de preservación y a la generación de metadatos, tal y como se describe en http://uc3m.libguides.com/ld.php?content_id=31389625. En la carpeta incluímos el archivo plantilla_tfg_2017.xmpdata en el que puedes incluir los metadatos que se incorporarán al archivo PDF cuando lo compiles. Ese archivo debe llamarse igual que tu archivo .tex. Puedes ver un ejemplo en esta misma carpeta.
\usepackage[a-1b]{pdfx}

% ENLACES
\usepackage{hyperref}
\hypersetup{colorlinks=true,
    linkcolor=black, % enlaces a partes del documento (p.e. índice) en color negro
    citecolor=black,
    urlcolor=blue} % enlaces a recursos fuera del documento en azul

% EXPRESIONES MATEMATICAS
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{booktabs}

\usepackage{txfonts}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[spanish, es-tabla]{babel}
\usepackage[babel, spanish=spanish]{csquotes}
\AtBeginEnvironment{quote}{\small}

% diseño de PIE DE PÁGINA
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\rfoot{\thepage}
\fancypagestyle{plain}{\pagestyle{fancy}}

\usepackage{eurosym}

% DISEÑO DE LOS TÍTULOS de las partes del trabajo (capítulos y epígrafes o subcapítulos)
\usepackage{titlesec}
\usepackage{titletoc}
\titleformat{\chapter}[block]
{\large\bfseries\filcenter}
{\thechapter.}
{5pt}
{\MakeUppercase}
{}
\titlespacing{\chapter}{0pt}{0pt}{*3}
\titlecontents{chapter}
[0pt]
{}
{\contentsmargin{0pt}\thecontentslabel.\enspace\uppercase}
{\contentsmargin{0pt}\uppercase}
{\titlerule*[.7pc]{.}\contentspage}

\titleformat{\section}
{\bfseries}
{\thesection.}
{5pt}
{}
\titlecontents{section}
[5pt]
{}
{\contentsmargin{0pt}\thecontentslabel.\enspace}
{\contentsmargin{0pt}}
{\titlerule*[.7pc]{.}\contentspage}

\titleformat{\subsection}
{\normalsize\bfseries}
{\thesubsection.}
{5pt}
{}
\titlecontents{subsection}
[10pt]
{}
{\contentsmargin{0pt}
    \thecontentslabel.\enspace}
{\contentsmargin{0pt}}
{\titlerule*[.7pc]{.}\contentspage}


% DISEÑO DE TABLAS. Puedes elegir entre el estilo para ingeniería o para ciencias sociales y humanidades. Por defecto, está activado el estilo de ingeniería. Si deseas utilizar el otro, comenta las lineas del diseño de ingeniería y descomenta las del diseño de ciencias sociales y humanidades
\usepackage{multirow} % permite combinar celdas
\usepackage{caption} % para personalizar el título de tablas y figuras
\usepackage{floatrow} % utilizamos este paquete y sus macros \ttabbox y \ffigbox para alinear los nombres de tablas y figuras de acuerdo con el estilo definido. Para su uso ver archivo de ejemplo
\usepackage{array} % con este paquete podemos definir en la siguiente linea un nuevo tipo de columna para tablas: ancho personalizado y contenido centrado
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\DeclareCaptionFormat{upper}{#1#2\uppercase{#3}\par}

% Diseño de tabla para ingeniería
\captionsetup[table]{
    format=upper,
    name=TABLA,
    justification=centering,
    labelsep=period,
    width=.75\linewidth,
    labelfont=small,
    font=small,
}

%Diseño de tabla para ciencias sociales y humanidades
%\captionsetup[table]{
%    justification=raggedright,
%    labelsep=period,
%    labelfont=small,
%    singlelinecheck=false,
%    font={small,bf}
%}


% DISEÑO DE FIGURAS. Puedes elegir entre el estilo para ingeniería o para ciencias sociales y humanidades. Por defecto, está activado el estilo de ingeniería. Si deseas utilizar el otro, comenta las lineas del diseño de ingeniería y descomenta las del diseño de ciencias sociales y humanidades
\usepackage{graphicx}
\graphicspath{{img/}} %ruta a la carpeta de imágenes

% Diseño de figuras para ingeniería
\captionsetup[figure]{
    format=hang,
    name=Fig.,
    singlelinecheck=off,
    labelsep=period,
    labelfont=small,
    font=small
}

% Diseño de figuras para ciencias sociales y humanidades
%\captionsetup[figure]{
%    format=hang,
%    name=Figura,
%    singlelinecheck=off,
%    labelsep=period,
%    labelfont=small,
%    font=small
%}


% NOTAS A PIE DE PÁGINA
\usepackage{chngcntr} %para numeración contínua de las notas al pie
\counterwithout{footnote}{chapter}

% LISTADOS DE CÓDIGO
% soporte y estilo para listados de código. Más información en https://es.wikibooks.org/wiki/Manual_de_LaTeX/Listados_de_código/Listados_con_listings
\usepackage{listings}

% definimos un estilo de listings
\lstdefinestyle{estilo}{ frame=Ltb,
    framerule=0pt,
    aboveskip=0.5cm,
    framextopmargin=3pt,
    framexbottommargin=3pt,
    framexleftmargin=0.4cm,
    framesep=0pt,
    rulesep=.4pt,
    backgroundcolor=\color{gray97},
    rulesepcolor=\color{black},
    %
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\bfseries,
    stringstyle=\ttfamily,
    showstringspaces = false,
    commentstyle=\color{gray45},
    %
    numbers=left,
    numbersep=15pt,
    numberstyle=\tiny,
    numberfirstline = false,
    breaklines=true,
    xleftmargin=\parindent,
    inputencoding = utf8,  % Input encoding
    extendedchars = true,  % Extended ASCII
    literate      =        % Support additional characters
      {á}{{\'a}}1  {é}{{\'e}}1  {í}{{\'i}}1 {ó}{{\'o}}1  {ú}{{\'u}}1
      {Á}{{\'A}}1  {É}{{\'E}}1  {Í}{{\'I}}1 {Ó}{{\'O}}1  {Ú}{{\'U}}1
      {ñ}{{\~n}}1
}

\captionsetup[lstlisting]{font=small, labelsep=period}
% fijamos el estilo a utilizar
\lstset{style=estilo}
\renewcommand{\lstlistingname}{\uppercase{Código}}


%BIBLIOGRAFÍA - PUEDES ELEGIR ENTRE ESTILO IEEE O APA. POR DEFECTO ESTÁ CONFIGURADO IEEE. SI DESEAS USAR APA, COMENTA LAS LÍNEA DE IEEE Y DESCOMENTA LAS DE APA. Si haces cambios en la configuración de la bibliografía y no obtienes los resultados esperados, es recomendable limpiar los archivos auxiliares y volver a compilar en este orden: COMPILAR-BIBLIOGRAFIA-COMPILAR

% Tienes más información sobre cómo generar bibliografía y CONFIGURAR TU EDITOR DE TEXTO para compilar con biber en http://tex.stackexchange.com/questions/154751/biblatex-with-biber-configuring-my-editor-to-avoid-undefined-citations , https://www.overleaf.com/learn/latex/Bibliography_management_in_LaTeX y en http://www.ctan.org/tex-archive/macros/latex/exptl/biblatex-contrib
% También te recomendamos consultar la guía temática de la Biblioteca sobre citas bibliográficas: http://uc3m.libguides.com/guias_tematicas/citas_bibliograficas/inicio

% CONFIGURACIÓN PARA LA BIBLIOGRAFÍA IEEE
\usepackage[backend=biber, style=ieee, isbn=false,sortcites, maxbibnames=5, minbibnames=1]{biblatex} % Configuración para el estilo de citas de IEEE, recomendado para el área de ingeniería. "maxbibnames" indica que a partir de 5 autores trunque la lista en el primero (minbibnames) y añada "et al." tal y como se utiliza en el estilo IEEE.

%CONFIGURACIÓN PARA LA BIBLIOGRAFÍA APA
%\usepackage[style=apa, backend=biber, natbib=true, hyperref=true, uniquelist=false, sortcites]{biblatex}
%\DeclareLanguageMapping{spanish}{spanish-apa}

% Añadimos las siguientes indicaciones para mejorar la adaptación de los estilos en español
\DefineBibliographyStrings{spanish}{%
    andothers = {et\addabbrvspace al\adddot}
}
\DefineBibliographyStrings{spanish}{
    url = {\adddot\space[En linea]\adddot\space Disponible en:}
}
\DefineBibliographyStrings{spanish}{
    urlseen = {Acceso:}
}
\DefineBibliographyStrings{spanish}{
    pages = {pp\adddot},
    page = {p.\adddot}
}

\addbibresource{references.bib} % llama al archivo bibliografia.bib en el que debería estar la bibliografía utilizada


%-------------
%    DOCUMENTO
%-------------

\begin{document}
\pagenumbering{roman} % Se utilizan cifras romanas en la numeración de las páginas previas al cuerpo del trabajo

%----------
%    PORTADA
%----------
\title{Práctica Final}
\author{Álvaro Guerrero Espinosa (100472294)\\
        César López Mantecón (100472092)\\
        Paula Subías Serrano (100472119)\\
        Irene Subías Serrano (100472108)\\}

\makeatletter
\begin{titlepage}
    \begin{sffamily}
    \color{azulUC3M}
    \begin{center}
        \begin{figure}[H] %incluimos el logotipo de la Universidad
            \makebox[\textwidth][c]{\includegraphics[width=16cm]{Portada_Logo.png}}
        \end{figure}
        \vspace{2.5cm}
        \begin{Large}
            Grado en Ingeniería Informática\\
            \@date\\
            \vspace{2cm}
            \textsl{Inteligencia Artificial en las Organizaciones}\\
            \bigskip
        \end{Large}
        {\Huge ``\@title''}\\
        \vspace*{0.5cm}
        \rule{10.5cm}{0.1mm}\\
        \vspace*{0.9cm}
        {\LARGE\@author}
        \vspace*{1cm}
    \end{center}
    \vfill
    \color{black}
    % si nuestro trabajo se va a publicar con una licencia Creative Commons, incluir estas lineas. Es la opción recomendada.
    \includegraphics[width=4.2cm]{creativecommons.png}\\ %incluimos el logotipo de creativecommons
    Esta obra se encuentra sujeta a la licencia Creative Commons \textbf{Reconocimiento - No Comercial - Sin Obra Derivada}
    \end{sffamily}
\end{titlepage}
\makeatother

\newpage %página en blanco o de cortesía
\thispagestyle{empty}
\mbox{}

%----------
%    ÍNDICES
%----------

%--
% Índice general
%-
\tableofcontents
\thispagestyle{fancy}

\newpage % página en blanco o de cortesía
\thispagestyle{empty}
\mbox{}

%--
% Índice de figuras. Si no se incluyen, comenta las lineas siguientes
%-
 \listoffigures
 \thispagestyle{fancy}

 \newpage % página en blanco o de cortesía
 \thispagestyle{empty}
 \mbox{}

%--
% Índice de tablas. Si no se incluyen, comenta las lineas siguientes
%-
\listoftables
 \thispagestyle{fancy}

 \newpage % página en blanco o de cortesía
 \thispagestyle{empty}
 \mbox{}


%----------
%    TRABAJO
%----------
\clearpage
\pagenumbering{arabic} % numeración con múmeros arábigos para el resto de la publicación

    \chapter{Introducción}
    \label{chap:intro}

    En este documento se recoge el desarrollo y conclusiones del proyecto final
    de la asignatura \textit{Inteligencia artificial en las organizaciones}.

    En el ámbito del deporte, el análisis del rendimiento ha sido
    tradicionalmente una tarea realizada por entrenadores y analistas, quienes
    observan los partidos para evaluar las acciones y estrategias de los
    jugadores. Sin embargo, este proceso es subjetivo, requiere tiempo y puede
    verse afectado por sesgos humanos. Con los avances recientes en
    inteligencia artificial (IA) y visión por computadora, se abren nuevas
    oportunidades para automatizar y mejorar el análisis deportivo,
    proporcionando una evaluación más objetiva, detallada y rápida.

    El voleibol es un deporte caracterizado por su velocidad, coordinación de
    varios jugadores y variedad táctica. La evaluación precisa de las acciones
    es una tarea fundamental para optimizar el desempeño tanto individual como
    colectivo. En este contexto, una IA capaz de reconocer y analizar
    secuencias del juego tiene el potencial de transformar la forma en la que
    se estudian los partidos, optimizando el proceso. 

    Este trabajo de investigación explora el desarrollo y aplicación de una
    inteligencia artificial entrenada específicamente para evaluar acciones de
    voleibol en vídeo. La propuesta combina algoritmos ámpliamente
    desarrollados para el reconocimiento de imágenes como YOLO~\cite{YOLO} y
    técnicas de análisis deportivo.

 

    \chapter{Estado del arte}
    \label{chap:estadoarte}

    \section{Reconocimiento de acciones y objetos}
    El área de la visión artificial se ha visto desarrollada en gran manera en
    los últimos años gracias al desarrollo del deep learning. El deep learning
    simula el razonamiento del cerebro humano, permitiendo a varias capas
    computacionales procesar información. Esto lleva a una captura de patrones
    y estructuras mucho más efectiva, sobre todo en áreas como el
    reconocimiento de imágenes. Permite analizar inmensas cantidades de
    imágenes para encontrar patrones que permitan la clasificación o detección
    de objetos, tareas de la visión artificial en las que se va a centrar este
    trabajo.  En específico, se va a utilizar la familia de algoritmos YOLO,
    basados en el tipo de deep learning conocido como redes neuronales
    convolucionales. YOLO, o You Only Look Once, destaca por su rápidez aun
    manteniendo un alto grado de precisión, cualidad obtenida gracias a su
    funcionamiento único de detección en un solo paso~\cite{JIANG20221066}. Los algoritmos de
    detección de objetos suelen dividirse en dos pasos: reconocimiento de
    objetos y clasificación de estos. La realización de estos dos pasos
    requiere de un tiempo y poder computacional adicional, siendo estos siempre
    secuenciale. YOLO, sin embargo, cuenta con la habilidad de realizar el
    reconocimiento y clasificación al mismo tiempo, lo cual lo determina como
    una de las mejores opciones en tareas de reconocimiento en tiempo real. Es
    por esto junto con la facilidad de entrenamiento y uso que proporciona
    ultralystics que se decide la utilización de esta herramienta.

    \section{La IA en el deporte}
    La inteligencia aritificial ha tenido una gran evolución en los últimos
    años, expandiéndo su uso a diferentes áreas nunca antes imaginadas. El
    mundo del deporte no ha sido una excepción, siendo la IA una herramienta de
    gran potencial para el la comprensión profunda del rendimiento
    deportivo~\cite{ia-sport}. Algunos ejemplos de su uso son el análisis de
    imágenes 3D para la mejora del rendimiento deportivo~\cite{analysis3d} o la
    planificación de cargas~\cite{wl}. 

    En cuanto al uso de IA en el voleibol, existen modelos con la capacidad de
    reconocer diferentes acciones del juego, destacando el estudio realizado
    para el diario \textit{Multimodal Technologies and
    Interaction}~\cite{wearable} para reconocer los diferentes gestos a través
    de sensores de tipo \textit{wearable}. Adicionalmente, también existen
    otras aplicaciones como SAETA~\cite{SAETA}, un modelo desarrollado por
    Javier Vales-Aloson et. al. para  la asistencia a entrenadores y atletas.


    Sin embargo, el análisis deportivo de estadísticas sigue siendo una
    actividad hecha manualmente donde la inteligencia artificial puede tomar un
    rol de gran relevancia.


    \section{Toma de estadísticas en el voleibol}
    En el voleibol español se emplean principalmente dos
    métodos para la toma de estadísticas de partidos según cuándo se realice:
    \begin{itemize}
        \item Toma de estadísticas en tiempo real: durante los partidos una o
        varias personas toman estadísticas manualmente o a través de
        herramientas especializadas.
        \item Toma de estadísticas en diferido: se graba el partido y
        posteriormente se revisa la grabación tomando estadísticas.
    \end{itemize}

    Ambas aproximaciones presentan claros problemas, especialmente hablando del
    groso de equipos federados que no cuentan con recursos suficientes para que
    esta actividad presente ventajas frente al esfuerzo que requiere. Hablando
    en concreto de Madrid, existen 99 clubes~\cite{directorio-clubes} y más de
    6000 deportistas~\cite{estadisticasFEVB}; mientras que sólamente hay
    201 técnicos (entrenadores y auxiliares)~\cite{estadisticasFEVB}. Esto
    refleja el claro desbalance que existe entre técnicos y deportistas, lo que
    hace imposible que muchos clubes cuenten con los recursos suficientes para
    la toma de estadísticas de forma eficiente.

    \subsection{Toma de estadísticas en tiempo real}
    
    Esta aproximación se suele tomar en equipos profesionales y a través de
    herramientas específicas. La toma de estadísticas suele realizarse por 3 o
    5 técnicos para su posterior publicación. Esto se hace mediante el programa
    \textit{Data volley}~\cite{datavoley}, un software especializado cuya
    licencia más económica parte de los 299\euro. 

    En equipos no profesionales, dependiendo del nivel de la competición, se
    suele tener un primer y un segundo entrenador. El primer entrenador dirige
    al equipo durante el encuentro y el segundo toma unas estadísticas
    reducidas y asesora al primero en otros menesteres. En equipos donde no
    existe la figura del segundo entrenador lo normal es no tomar estadísticas
    durante el encuentro.

    \subsection{Toma de estadísticas en diferido}

    La toma de estadísticas en diferido es la aproximación habitual para
    equipos con un único entrenador. Esta forma de tomar estadísticas presenta
    2 problemas: la falta de tiempo y la iniciativa individual.

    Respecto a la falta de tiempo, es importante entender que el voleibol en
    españa es un deporte minoritario. Además, un partido de voleibol puede durar
    entre 45 y 180 minutos según la categoría. El análisis del metraje y la
    toma de estadísticas puede multiplicar este tiempo por un factor de entre 3
    y 5 de manera habitual. Esto sumado a que la mayoría de entrenadores no
    tienen el voleibol como fuente de ingresos principal y que deben combinar
    su actividad como técnicos deportivos con otras actividades se
    traduce en que a muchos entrenadores les resulte imposible invertir su
    tiempo en revisar las grabaciones y tomar estadísticas de sus equipos.

    Adicionalmente, la mayoría de pabellones y clubes no cuentan con la
    infraestructura (cámaras, trípodes y espacio) necesaria para obtener
    grabaciones de buena calidad que puedan ser fácilmente analizadas. Por esto, 
    un gran porcentaje de los entrenadores que realizan la toma de estadísticas
    en diferido lo hacen por iniciativa propia. Esto desincentiva la actividad,
    haciendo de la toma de estadísticas en diferido un lujo que pueden
    permitirse sólo los clubes con mayor poder adquisitivo para facilitar la
    infraestructura a sus entrenadores.
    
    
    \chapter{Objetivo}
    \label{chap:metodos}

    El objetivo principal de este proyecto es desarrollar un sistema que
    permita la toma de estadísticas de voleibol a partir de secuencias de
    vídeo, ofreciendo una solución accesible y eficiente para clubes con
    recursos limitados. Este sistema busca automatizar el análisis de partidos,
    reduciendo significativamente la carga de trabajo manual que actualmente
    recae sobre los entrenadores, especialmente en equipos no profesionales
    donde el tiempo y los recursos son escasos.

    Dado que el estudio se trata de una primera aproximación a este problema,
    el modelo se centra en el análisis y evaluación del gesto técnico de
    colocación o armado. Se ha elegido esta acción por tratarse de la base de
    todos los sistemas de juego de este deporte, además de ser la más
    determinante para lograr la efectividad en el juego.

    Además, se pretende que esta herramienta sea adaptable a diferentes niveles de
    competición, considerando las limitaciones en la calidad de las grabaciones y
    la infraestructura de los clubes. Al facilitar la recopilación de estadísticas
    precisas y útiles, este proyecto puede contribuir al crecimiento y la
    profesionalización del voleibol en España, fomentando la igualdad de
    oportunidades entre equipos con diferentes capacidades económicas.


    \chapter{Análisis de datos}
    \label{cahp:datos}
    Para la realización del proyecto se han utilizado tres conjuntos de datos.
    El primero cuenta con 4835 secuencias extraídas de 55 vídeos
    de partidos de voleibol profesional. Cada secuencia está compuesta de 41
    frames~\cite{dataset1}. 
    Para cada secuencia se etiqueta la acción realizada durante
    la secuencia, con uno de los siguientes valores: \verb!l-spike!,
    \verb!r_spike!, \verb!r-pass!, \verb!l_winpoint!, \verb!l_set!,
    \verb!l-pass!, \verb!r_winpoint! o \verb!r_set!. Además, también se etiqueta
    la posición y acción de cada jugador durante los frames 11 a 30. Esto se
    hace con una 10-tupla con los valores ID del jugador, \verb!xmin!,
    \verb!ymin!, \verb!xmax!, \verb!ymax!, ID del frame en su video,
    \verb!lost!, \verb!grouping!, \verb!generated! y tipo. \verb!xmin!,
    \verb!ymin!, \verb!xmax! e \verb!ymax! definen el rectangulo en el que se
    encuentra el jugador, y el tipo puede tomar uno de los siguientes valores:
    \verb!waiting!, \verb!setting!, \verb!blocking!, \verb!spiking!,
    \verb!standing!, \verb!falling!, \verb!jumping!, \verb!moving! o
    \verb!digging!. Por último, \verb!lost! indica si el rectangulo anotado está
    fuera del campo de visión, \verb!grouping! indica si el jugador está
    involucrado en la acción principal, y \verb!generated! indica si el
    rectangulo fue automáticamente interpolado.

    \begin{table}[H]
        \begin{tabular}{@{}cc@{}}
            \toprule
            Acción & Num. Instancias\\
            \midrule
            Colocación    & 1276\\
            Remate        & 1265\\
            Pase          & 1627\\
            Punto Ganador &  662\\
            \bottomrule
        \end{tabular}
        \caption{Distribución de secuencias por gesto para el primer conjunto de datos.}
    \end{table}

    La segunda base de datos~\cite{dataset2} utiliza el mismo conjunto de videos y secuencias,
    pero etiqueta la posición $x$ e $y$ del centro de la bola en cada frame de
    cada secuencia. Debido a esto, se puede combinar con la primera base de
    datos para obtener todos los datos que necesitamos. En los casos en los que
    la bola no se puede ver claramente (ya sea por que está oculta o porque se
    mueve demasiado rápido), la etiqueta corresponderá con la localización
    estimada de la bola.

    Finalmente, el tercer conjunto de datos cuenta con 1380 imágenes en las que
    se muestra un balón de voleibol en diferentes escenarios y
    contextos~\cite{dataset3}. Este dataset permite un entrenamiento breve y de
    gran variedad de imágenes con el fin de construir modelos capaces de
    reconocer un balón de voleibol en contextos donde la luminosidad o calidad
    de imágenes no estén a la altura de vídeos profesionales.

    \chapter{Metodología}
    \label{chap:metodologia}
    En este capítulo se describirán los difentes procesos llevados a cabo para la construcción y evaluación del modelo. Todos los \textit{scripts} mencionados han sido incluídos en el \hyperref[anexo]{Anexo}.

    \section{Filtrado de datos y etiquetado}

    Este proyecto se centrará en uno de los gestos técnicos, la colocación o
    armado, con el fin de reducir el alcance de la práctica. Los datos obtenidos
    de la primera base de datos han sido filtrados y reducidos a las secuencias
    de las clases \verb!r_set! o \verb!l_set!, utilizando un programa de
    \verb!python!. Esto reduce el número de
    secuencias a 1276.

    Cada secuencia ha sido etiquetada manualmente en las clases positiva
    (representada con el símbolo \verb!+!) y negativa (representada con el
    símbolo \verb!-!) siguiendo el siguiente criterio:
    \begin{itemize}
        \item \textbf{Positiva:} se clasifica una colocación como positiva si
        el jugador ha conseguido realizar un pase con la yema de los dedos de
        ambas manos.
        \item \textbf{Negativa:} se clasifica una colocación como negativa si
        el jugador no ha logrado realizar un pase con la yema de los dedos,
        golpeándo el balón con el antebrazo o empleando una sóla mano.
    \end{itemize}
    
    Dado que existen un gran número de secuencias positivas frente a las
    negativas, se ha usado un \textit{script} de \texttt{bash} (ver
    \ref{preclasificado}) para realizar un preclasificado de las secuencias.
    Además, ha sido necesario modificar la segunda base de datos para incluir
    el tamaño de la \textit{bounding box} para cada balón. Esto último se ha
    hecho a través de un programa de \texttt{Python}. Se ha escogido un 
    tamaño genérico igual para todas las instancias ($20px\times20px$).

    Las secuencias se han separado en dos carpetas, cada una conteniendo las
    imágenes de cada una de las clases. Adicionalmente, para cada carpeta se
    han dividido las secuencias en subconjuntos de entrenamiento y evaluación.
    Para esto se ha usado un programa en \texttt{Python}.

    Adicionalmente se ha creado una clase más denominada \textit{wait} para
    aquellos frames que no aporten información relativa al tipo de acción. Se
    compararán los resultados obtenidos empleando y sin emplear esta clase.

    \section{\textit{Oversampling} y \textit{Undersampling}}

    Los datos cuentan con un desbalanceo muy fuerte hacia la clase positiva: tan
    solo un $2.59\%$ de las instancias están etiquetadas como negativas. Debido
    a esto, se ha decidido realizar tanto un \textit{oversampling} de la clase
    minoritaria como un \textit{undersampling} de la clase mayoritaria. 

    \subsection{Oversampling}

    Para el oversampling se ha usado la librería de python
    Albumentations~\cite{albumentations}, que permite aplicar transformaciones a imágenes
    para crear nuevas instancias, mediante el uso de redes neuronales profundas.
    
    Para generar nuevas instancias se han aplicado entre 1 y 9 transformaciones
    seleccionadas de forma aleatoria a caada imagen, generando 4
    nuevas instancias por cada secuencia. Para ello se ha elaborado un código
    python que toma todas las imágenes de una carpeta y aplica este proceso a
    cada una.

    El proceso seguido para cada imagen es el siguiente: 
    \begin{enumerate}
        \item Generación aleatoria de un número entre 1 y 9: este número respresenta el número de transformaciones que se aplicarán a la imagen.
        \item Aplicación de las transformaciones: mediante la función \texttt{SomeOf} se aplica un subconjunto de las 20 transformaciones seleccionadas.
    \end{enumerate}
    Estas operaciones se repiten 4 veces para cada imagen.

    Adicionalmente, se han castigado números altos de transformaciones debido a
    que podrían generar imágenes demasiado distorsionadas y, por tanto, no
    óptimas para el entrenamiento. Para ello se ha añadido una probabilidad a
    la aplicación de una transformación como se describe a continuación:

    \begin{table}[H]
    \centering
        \begin{tabular}{cc}
        \toprule
        \textbf{\# transformaciones} & \textbf{Probabilidad} \\
        \midrule
        Entre 1 y 3 & 1.0\\
        Entre 4 y 5 & 0.6\\
        Entre 6 y 9 & 0.3\\
        \bottomrule
        \end{tabular}
    \caption{Probabilidad según el número de transformaciones}
    \end{table}

%    número aleatorio entre uno y nueve que se inserta en una \textit{pipeline}
%    que utiliza el comando de Albumentations \textit{SomeOf}, que contiene una
%    lista de veinte posibles transformaciones de las cuales se aplicará el
%    número obtenido previamente. Se ha decidido castigar números altos de
%    transformaciones ya que realizar demasiadas de estas puede llevar a obtener
%    una imagen demasiado distorsionada. Esto se ha realizado asignando a cada
%    transmación cierta probabilidad de aplicarse, siendo 1 que siempre se
%    aplica y 0 que nunca. Cuando el número de transformaciones elegido es de 1
%    a 3 la probabilidad será 1, si es 4 o 5 será 0.6 y si es 6 o más será 0.3. 

    A pesar de existir un gran número de transformaciones en la librería
    Albumentations se han seleccionado únicamente 20 de estas. Esto se debe a
    que muchas transformaciones generan instancias demasiado alejadas de las
    condiciones habituales en los centros deportivos (e.g. simulación de nieves
    o inversión de color), lo que podría ensuar el conjunto de datos. A
    continuación se enumeran las transformaciones seleccionadas:

    \begin{enumerate} \item \textbf{CLAHE:} esta transformación, cuyas siglas
    significan \textit{Contrast Limited Adaptive Histogram Equalization},
    mejora el contraste de una imagen. Se ha elegido debido a que pueden darse
    instancias en las que debido a los ajustes de una cámara las imágenes
    tengan diferentes contrastes.
    \item \textbf{ChromaticAberration:} la
    transformación simula una cámara que no ha enfocado todos los colores al
    mismo punto por lo que algunos de los colores aparecen desfasados de otros,
    en este caso el azul y rojo están desfasados del verde.
    \item \textbf{ColorJitter:} modifica le brillo, el contraste, la saturación y el
    tono, que pueden cambiar dependiendo de factores como la iluminación. Por
    esto se ha considerado una transformación posible aunque el rango de
    transformación del tono definido es muy pequeño ya que se quería simular
    cambios ligeros por iluminación o calibración de la cámara no camabios
    grandes no comunes.
    \item \textbf{Downscale:} reduce la calidad de la
    imagen reduciendo su tamaño y volviendo a aumentarlo.  Variaciones de
    calidad de una imagen dependen de la cámara usada por lo que se ha
    considerado una situación posible en una instancia obtenida de manera
    natural.
    \item \textbf{Emboss:} realza la imagen destacando los bordes de
    los objetos y creando una textura 3D, efecto obtenible con los ajustes de
    una cámara.
    \item \textbf{Equalize:} ecualiza el histograma de la imagen,
    ajustando su contraste para que los diferentes tonos de grises tengan el
    mismo número de pixeles. Este es otro efecto que puede aparecer
    naturalmente debido a ajustes de la cámara.
    \item \textbf{GaussNoise:}
    inserta ruido en la imagen siguiendo una distribución gausiana. Una imagen,
    sobretodo si no es de mucha calidad, puede tener ruido naturalmente, esta
    transformación imita esto.
    \item \textbf{HorizontalFlip:} refleja la foto
    sobre su eje vertical, creando nuevas instancias que son iguales a las
    originales pero reflejadas.
    \item \textbf{HueSaturationValue:}
    transformación similar a ColorJitter que a diferencia de esta no modifica
    el contraste, solo el valor, equivalente al brillo; la saturación y el
    tono.
    \item \textbf{ISONoise:} crea ruido que simula el ruido creado por
    diferentes ajustes de exposición de una cámara.  Simula los dos componentes
    principales del ruido ISO: cambios aleatorios en el tono de los colores y
    variaciones aleatorias en intensidad de los pixeles.
    \item \textbf{ImageCompression:} decrementa la calidad de la imagen
    comprimiendola a un formato "jpeg". Simula casos en los que las imagenes
    son de peor calidad.
    \item \textbf{Morphological:} aumenta el grosor de
    zonas blancas de la imagen, simulando una mayor iluminazión de la zona.
    \item \textbf{PlanckianJitter:} simula variaciones de temperatura de la luz
    en una imagen que en este caso sería el tono de las luces de la pista.
    \item \textbf{Posterize:} reduce el número de bits para cada color en una
    imagen. El efecto final es de una imagen que ha perdido calidad y se han
    unificado algunos colores.
    \item \textbf{RGBShift:} la transformación
    modifica aleatoriamente e individualmente los canales RGB de la imagen.  El
    rango de modificación que se ha definido es pequeño ya que solo se busca
    obtener imagenes con ligeras variaciones que podrían ser probocadas por el
    tipo de luz o por la cámara usada.
    \item \textbf{RandomBrightnessContrast:} cambia el brillo y contraste de la
    imagen, creando instancias de como sería la imagen en otras condiciones
    lumínicas.
    \item \textbf{RandomGamma:} similar a la transformación
    anterior pero modificando el Gamma. Con esto se asegura que aunque cambie
    el brillo la relación entre claros y oscuros se mantendrá.
    \item \textbf{RandomToneCurve:} manipula la curva del tono cambiando la relación
    entre las zonas oscuras y las claras de la imagen. Simula diferentes
    intensidades de iluminación de la pista.
    \item \textbf{RingingOvershoot:}
    hace borrosos los limites de los objetos de una imagen. En este caso se
    aplica porque simula como sería una imagen si la cámara estuviera
    desenfocada.
    \item \textbf{Sharpen:} utiliza interpolado para "afilar" la
    imagen. Hace que los bordes sean más pronunciados pero como efecto
    secundario lleva a que se pierda calidad de la imagen.
    \end{enumerate}

    \subsection{Undersampling}

    Se ha menguado el conjunto de datos de instancias positivas en un 50\%. Esto permite una mayor proporción de instnacias negativas, mantiendo una gran representatibidad de la clase positiva.

    \subsection{Resultados}

    Gracias a este proceso se ha conseguido pasar de una proporción menor al 3\% de instancias negativas a una proporción superior al 20\%. En los siguientes diagramas se puede apreciar visualmente la distribución de los datos: 

\begin{minipage}{0.45\textwidth}
    \begin{figure}[H]
    \includegraphics[width=0.4\textwidth]{datos-prev.jpg}
    \caption  {\small{Distribución previo al proceso de oversampling y undersampling}}
    \end{figure}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}{0.45\textwidth}
    \begin{figure}[H]
    \includegraphics[width=0.45\textwidth]{datos-post.jpg}
    \caption  {\small{Distribución posterior al proceso de oversampling y undersampling}}
    \end{figure}
\end{minipage}

    \section{Entrenamiento: modelos de YOLO}

    Durante el entrenamiento se han creado tres modelos distintos mediante el
    uso del algoritmo ``You Only Look Once'' (YOLO){biblio}, basado en redes de
    neuronas convolucionales. Dos de estos modelos buscan clasificar videos en
    jugadas correctas o erróneas, mientras que el tercero pretende detectar la
    pelota y seguirla en estos videos. Se ha decidido utilizar YOLO por la
    facilidad, rapidez y precisión que este proporciona para crear modelos
    propios de detección y clasificación de imágenes, siendo una de las
    tecnologías principales en el área del Computer Vision. YOLO Permite crear
    modelos fácilmente entrenables de manera rápida y eficiente{bibliografia}
    con imágenes propias. Para ello es necesario especificar cada clase como un
    directorio que contenga todas las imágenes de dicha clase. Dentro de este
    directorio se pueden separar las imágenes en otros dos: uno de
    entrenamiento y, opcionalmente, otro de validación. La estructura interna
    de estas carpetas variará dependiendo del tipo de modelo que se vaya a
    utilizar. Los modelos han sido entrenados con 100 \textit{epochs} con el
    fin de lograr suficiente precisión en un tiempo de entrenamiento limitado.

    Tanto para el problema de clasificaicón como el de detección y seguimiento
    se parte de un modelo preentrenado, al que se especializa a través del
    entrenamiento con nuestros conjuntos de datos. Esto evita la necesidad de
    crear un modelo completamente nuevo, facilitando el desarrollo y mejorando
    los resultados. Es por esto que se trata de una práctica recomendada por
    \textit{Ultralytics}.

    \subsection{Clasificación}
    Para la clasificación de secuencias se ha partido desde el modelo
    \texttt{yolo11n-cls.pt}~\cite{yolo11n-csl}, un modelo preentrenado para la
    clasificación de fotogramas donde la clase de la secuencia será la clase
    mayoritaria de sus fotogramas. Esto presenta una clara desventaja: los
    fotogramas se clasifican de forma independiente. Esto se traduce en que el
    modelo no buscará relación entre fotogramas y, por tanto, no identifica la
    acción completa. Adicionalmente, la acción ocurre en apenas 8 fotogramas,
    frente a los 41 que dura la secuencia, lo que podría provocar un desajuste
    en la predicción.
    
    Con el fin de mermar todo lo posible este problema, se han trabajado con
    dos aproximaciones diferentes para la clasificación: 

%    En este caso se utiliza un modelo preentrenado como base,
%    ``yolo11n-cls.pt''~\cite{yolo11n-csl}, siguiendo la recomendación de Ultralytics para el
%    entrenamiento de YOLO. Esto evita
%    la necesidad de crear un modelo desde cero, siendo necesario sólo la
%    definición de las clases. Para  esto es necesario crear una carpeta de
%    imágenes para cada una de las clases dentro de las carpetas de
%    entrenamiento y test antes mencionadas. 
%    
%    Yolo presenta una desventaja principal en el problema de la clasificación
%    de videos: trabaja con fotogramas independientes, asignando a cada
%    fotograma de entrada una clase sin tener en cuenta la clasificación del
%    resto del video. Esto provoca que no exista una identificación de la acción
%    completa, lo cual se teoriza que puede causar problemas sobre todo en
%    acciones como las deportivas, en las que la diferencia entre una jugada
%    correcta y una incorrecta se define en dos o tres fotogramas claves. Por
%    esto, se plantean dos aproximaciones a la clasificación de videos:

    \begin{enumerate}
        \item \textbf{Modelo de clasificación binario:} con clases ``correct'' y ``wrong'', que dividen todas las jugadas dependiendo de la corrección de estas.
        \item \textbf{Modelo de tres clases:} Con una clase adicional correspondiente con los momentos de espera antes y después de la acción.
    \end{enumerate}

    Con el segundo modelo se busca agrupar los fotogramas donde no ocurre la
    acción en una tercera clase que \textbf{no se tomará en cuenta} para la
    clasificación de la secuencia. De esta forma se espera poder construir un
    modelo más robusto y fiel a la realidad.

    Con todo lo anterior, las clases de cada modelo qeudan representadas por la siguiente estructura de ficheros:

    \begin{figure}[H]
        \includegraphics[width=0.4\textwidth]{folders_binario.jpeg}
        \hspace{0.3cm}
        \includegraphics[width=0.4\textwidth]{folders_ternario.jpg}
        \caption {Organización de directorios para clasificación}
    \end{figure}

%    Este segundo modelo busca corregir el problema que se puede encontrar al ser los fotogramas externos a los instantes de la acción virtualmente idénticos independientemente de la clasificación de esta. Esto se teoriza que puede provocar que el modelo confunda ambas clases en las predicciones de estos fotogramas y no se consigan resultados precisos.
    
    \subsection{Detección de objetos}
    Se crea un modelo utilizando la tarea de Detección y Seguimiento de YOLO{aqui tengo que poner biblio}, con el objetivo de colocar una ``caja'' que marque el recorrido de la pelota en un video. Esto sirve de ayuda visual a estadisticos o analistas de partidos sobre todo en competiciones masculinas, donde la bola puede alcanzar velocidades de hasta 140 km/h. 

    Como primera aproximación, se intentó usar el segundo conjunto de datos presentado anteriormente. Sin embargo, la limitación en potencia de cómputo de nuestras máquinas hacía de este algo imposible por la gran duración del proceso de entrenamiento. En consecuencia, se ha empleado el tercer conjunto de datos. Este conjunto presenta además otras ventajas como es la mayor variabilidad de condiciones en las imágenes (luminosidad, contraste, fondos...), que se asemejan más a las condiciones que se puenden encontrar en pabellones comunes de competiciones de bajo nivel.

    Siguiendo el mismo proceso que para la clasificación, se ha partido de un modelo preentrenado para la detección y seguimiento de objetos: \texttt{yolo11n.pt}~\cite{yolo11n}. Para su correcto funcionamiento se han dividido las imágenes en dos directorios, \textit{train} y \textit{test}, y se han definido las características específicas de nuestro modelo en el fichero \textit{data.yaml}. 

    % Para esto se consideró la creación de un modelo completamente nuevo a través de la anotación de la posición de la pelota en todos los fotogramas de los videos. Sin embargo, esta tarea se consideró demasiado compleja para el alcance de la práctica, siendo necesario anotar más de diez mil imágenes.
    %Por ello, para este modelo se ha buscado un modelo personalizado para la detección de pelotas de voleibol ya creado. Se ha encontrado así un conjunto de imágenes ya anotadas con alrededor de mil ejemplos de pelotas de voleibol en entornos y calidades completamente diferentes{aqui también biblio}. Esta se considera una buena base para el modelo de detección que se quiere lograr, que utilizará estos datos por encima de un modelo preentrenado de yolo ``yolo11n.pt''. En este caso las imágenes solo necesitan estar dentro de las carpetas de entrenamiento y test, pero se añade un fichero adicional ``data.yaml'' que define el objeto a encontrar además de la ruta de las carpetas usadas en el entrenamiento. 
    

    \section{Evaluación}

    Para la evaluación se emplearán dos medidas, principalemente. La primera,
    la función \textit{Loss}, que mide como de mala es una predicción. La
    segunda, la matriz de confusión, muestra los valores predichos para cada
    una de las clases. En esta última, trataremos de reducir los falsos
    negavitos. También se emplearán los datos de salida de YOLO, que incluyen
    la clasificación de cada fotograma, el nivel de confianza medio, el
    porcentaje de cada clase sobre el total de fotogramas y la precisión del
    modelo.

    Adicionalmente, se han recogido vídeos de un equipo femenino de categoría
    juvenil durante un entrenamiento con el fin de enfrentar al modelo a un
    caso de uso real y comprobar su capacidad de generalización a otras categorías.
%
%    - Tras clasificar cada fotograma por separado, el video corresponde con la clase mayoritaria. En el caso de tres clases "waiting" será contada en el porcentaje pero no en la clasificación final. Se consigue información de número de fotogramas clasificados como correctos e incorrectos, el porcentaje que representan del total, así como la confianza media del modelo en total del video.
%
%    - Si existe el mismo número de instancias positivas y negativas se considera el resultado como no concluyente.
%
%    - Matriz de confusión, comprobar los falsos positivos o negativos, importancia minimizar los falsos incorrectos, pues esto son los más dañinos al considerar una acción correcta como erronea.
%
%    - Información de precisión proporcionada por YOLO, contiene información del mejor modelo durante el entrenamiento. Utiliza Loss, buena métrica para comprobar como de malas son las predicciones, se busca minimizar.
%
%    - Utilización de videos completamente independientes a los videos de entrenamiento grabados por el grupo, que son una buena opción para probar la capacidad de generalización del modelo.
%

    \chapter{Análisis de resultados}
    \label{chap:resultados}

    \chapter{Trabajos futuros}
    \label{chap:future}

    De cara a la expansión de este proyecto y el desarrollo de futuros modelos
    más completos, destacan varios retos que están pendientes de resolver.

    Primero, el reconocimiento de otros elementos del juego como jugadores,
    superficie de juego o árbitros; de la mano con la mejora en el seguimiento
    del balón. Esto permitiría análisis más completos de los partidos y
    facilitaría tareas como el análisis de los sistemas de defensa o bloqueo,
    transiciones entre fases del juego o extracción de características de
    equipos. Además, sería un primer paso de cara a la automatización del
    análisis de partido, extrayendo cualidades clave del juego en forma de
    datos organizados y fácilmente procesables.

    Segundo, la mejora de la precisión de la clasificación. Esto permitiría la
    toma de estadísticas de forma automática, resolviendo o facilitando la
    situación de clubes de pocos recursos tanto en tiempo como económicos. Para
    ello, se propone la construcción de un conjunto de datos más completo,
    recolectando partidos de distintas categorías y niveles con el fin de
    permitir una mejor generalización de los modelos.

    Por último, la clasificación de secuencias completas en lugar de fotogramas
    individuales. Pese a que se aprecia potencial en la clasificación por
    fotogramas, explorar la posibilidad de desarrollar un clasificador de
    secuencias que encuentre y entienda las relaciones entre imágenes es un
    reto que no se ha podido resolver durante este proyecto.
    

    \chapter{Conclusiones}
    \label{chap:conclusion}

    Los modelos elaborados, pese a tener un rendimiento por debajo de lo deseable, muestran el gran potencial de la inteligencia artificial para cubrir las necesidades en el mundo del deporte. Sin embargo, también muestran la necesidad de una mayor inversión en investigación y exploración de otros métodos. De la mano con otros autores, durente este proyecto se ha demostrado que la IA puede automatizar muchos procesos que antes se creían imposible, abaratando costes y facilitando el desarrollo de actividades profesionales en deportes minoritarios. 

    También es destacable la importancia de la potencia de cómputo en el entrenamiento de modelos complejos. Este ha sido el principal limitante de este proyecto. No obstante, en un contexto con mayores recursos la metodología descrita en este documento podría demostrar un mayor rendimiento gracias a un entrenamiento más extenso y completo.

    Por último, cabe resaltar que el principal problema encontrado en los modelos de clasificación es la poca capacidad de generalización. Esto es un ámbito multifactorial que requiere de una mayor exploración para alcanzar un mejor rendimiento a través de la optimización de hiperparámetros o de la aplicación del conjunto de entrenamiento.

    En cuanto al modelo de seguimiento de balón, se ha logrado desarrollar un modelo que funciona adecuadamente en contextos de entrenamiento. Esto tiene un gran potencial como asistencia a entrenadores y técnicos en el voleibol. Adicionalmente, cabría esperar que un mejor entrenamiento con un set de datos más extenso podría dar muy buenos resultados.

    Por último, nos gustaría terminar este proyecto agradeciendo a las jugadoras María Ortega y Marta Jiménez su colaboración en la grabación de vídeos en los entrenamientos.

    %----------
    %    BIBLIOGRAFÍA
    %----------

    %\nocite{*} % Si quieres que aparezcan en la bibliografía todos los documentos que la componen (también los que no estén citados en el texto) descomenta está lína

    \clearpage

    \phantomsection
    \addcontentsline{toc}{chapter}{Bibliografía}
    \label{chap:bibliography}
    \setquotestyle[english]{british} % Cambiamos el tipo de cita porque en el estilo IEEE se usan las comillas inglesas.
    \printbibliography

    %----------
    %    ANEXOS
    %----------

    % Si tu trabajo incluye anexos, puedes descomentar las siguientes lineas
    \phantomsection
    \chapter*{Anexo}
    \label{anexo}
    \pagenumbering{gobble} % Las páginas de los anexos no se numeran

    \phantomsection
    \section*{Código Python para filtrar la base de datos de acciones}
    \label{filtrado_script}
    \lstinputlisting[language=Python]{../scripts/filter.py}

    \phantomsection
    \section*{Código Python para añadir el tamaño de \textit{bounding box}}
    \label{mod_ball}
    \lstinputlisting[language=Python]{../scripts/process_ball_anotations.py}

    \phantomsection
    \section*{Código Python para la particición de las anotaciones en ficheros}
    \lstinputlisting[language=Python]{../scripts/split_lines.py}

    \phantomsection
    \section*{Código bash para el preclasificado}
    \label{preclasificado}
    \lstinputlisting[language=bash]{../scripts/preclasificado.sh}

    \phantomsection
    \section*{Código Python para la división por carpetas}
    \label{div_carpetas}
    \lstinputlisting[language=Python]{../scripts/split_videos.py}
\end{document}
